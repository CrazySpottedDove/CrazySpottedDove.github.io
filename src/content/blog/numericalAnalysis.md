---
title: 数值分析
description: 数值分析笔记
pubDate: 2025-02-19
updatedDate: 2025-02-19
tags: ["numerical analysis", "note"]
category: "课程笔记"
---

## Introduction

使用计算机计算和现实计算有一个显著差别：计算机计算的精度是有限制的。我们有不同的数据结构，带来不同的计算精度。数值分析这门课要求我们求出精度足够好的结果。它会告诉我们一些近似算法，同时也告诉我们，什么时候它们能用，什么时候又不能用。

我们轻而易举地就能想清楚加减乘除的原理。然而，我们可能没有注意 $\sin,\cos,\tan,\ln$ 是怎么实现的？数值分析这门课可以告诉我们背后的原理。

> 一个自然的想法：泰勒展开

## 数学上的准备

怎么求一个积分？简单的想法是把被积函数泰勒展开转化成多项式，然后利用其便于求积分的特性求解。然而，泰勒展开往往是无限的，这就需要我们规定一个提前结束的时机，这也引入了一个相当于泰勒余项(**Remainder**)的**误差**。这个误差就是我们需要注意的。

而且，一个棘手的点是：我们没有办法直接和真值进行比较！

另一个棘手的点是：每一个数值本身都与它自己的真值有误差，这也引入了新的误差！我们需要为每一个数据保留多少位，这也相应地成为了一个问题。

### 误差 Errors

* Truncation Error：与时间有关的一个误差。它代表近似数学引入的误差。

> 显式的操作，经典的就是一个`for`循环

* Roundoff Error：与空间有关的一个误差。它代表数字在计算机中的表达和数字本身的误差。

> 数据背后的误差

为了讨论方便，我们用十进制来表示数字。对于一个不嫩直接以有限数位表示的数字，有两种方式处理精度：

* 四舍五入(Rounding)
* 直接砍掉精度数位后面的位数(Chopping)
* 往上取

> 大学老师给分(不是)

误差也分为绝对误差(absolute error)和相对误差(relative error)

而有效数字(siginificant digits)应该是一个相对误差概念。可以注意到，对应数值的部分被移到了科学计数法中的指数部分。
> 有了有效数字的概念，我们应该把数字 0.123 看成 $0.123\pm\epsilon_1$
> 使用四舍五入的方法时，有效数字 0.1 的相对误差是 50%

那么，有一个现象，就是两个相近的数字相减之后，有效位数减小时，相对误差会显著增加。

将一个数除以一个很小的数，绝对误差会放大。这一点是符合直觉的。一个想法是把绝对误差看成两个数字的函数，然后取关于分母的导数，如果导数很大，那么就说明分母的轻微变化会带来较大的变化，也就是较大的误差。对于相对误差，也可以尝试以这样的方法进行分析。

计算的约化也要注意，计算机是每一个单元运算都会进行约化的，不能直接对最终结果进行约化。

也正是因此，虽然对单个数字而言，Rounding 会更精确，但是对于一个一连串的算式而言，未必。
> 我们此时也自然地想到，解不是确定值，也可能不是个区间，而应该是一个概率密度分布中的某个可能值。

也还是因此，对于同一个算式的不同表达，比如将一个算式通过一些方式结合，分配，也可以导致不同的误差。减少乘除的次数，有可能减少误差。减少单元计算的数量，也有可能减小误差。
> 数学上等价，不等于数值分析方法上等价！

我们可以手动求导来分析误差，也可以用一些自动求导的工具来分析计算式的误差。

### 算法和收敛 Algorithms and Convergence

当一个算法中，原始数据的较小变化只引起较小的终解的变化时，它是 stable 的；否则，它是 unstable 的。当它对于某些原始数据 stable 时，它是 conditionally stable 的。

设初始误差为 $E_1$，当做连续的 n 次操作时，如果误差 $E_n$ 约为 $E_1$ 的常数倍时，说误差的增长是 linear 的。如果 $E_n$ 约为 $E_1$ 的以常数为底的指数倍时，则说误差的增长是 exponent 的。

## 一元方程的求解

### 二分法

能使用二分法的前提是可排序。比如说，复数就很难使用二分，因为它没有既定的序。

二分法一定要除以二吗？不一定。只要区间收敛就好。

* 取中间位置时应该用`p=a+(b-a)/2`。
* 判断取左边界还是右边界时，需要用`sign()`，而非直接相乘看是否小于 0。
* 函数值需要考虑溢出问题。比如说，一个指数函数就容易出现溢出，即使它的横坐标是没溢出的。

如果二分法的区间取的过大，可能会忽略函数的根，如一个先增后减的区间，两侧都小于零，就会误认为中间没解了。

### 不动点迭代

把方程的根转化成一个等效的等式：$f(x)=0 \Leftrightarrow x=g(x)$。$g$ 的不动点是 $f$ 的根。

#### 不动点定理：Self

> 令 $g$ 是一个在 $[a,b]$ 连续的函数，且在其中 $g(x)\in[a,b]$。若对于它的导函数 $g'$，存在一个常数 $k\in(0,1)$ 使得开区间内任意的 $x$，有 $|g'(x)|\le k$，则对任意的 $p_0\in[a,b]$，序列 $p_n=g(p_{n-1})$ 收敛到唯一的不动点 $p\in[a,b]$。

* 利用中间值定理，证明存在不动点。
* 利用中值定理，证明不动点唯一。
* 利用值域被定义域包含的条件，保证迭代过程中，$g(x)$ 的结果始终在定义域中。
* 利用中值定理，证明迭代确实是收敛于那个存在且唯一的不动点。

这里的存在一个 $k\in(0,1)$ 很重要，这把 $g'(x)$ 和 1 隔开了，避免了极限为 1 的情况。

>看证明是有利于记忆定理的。在看证明的过程中，可以理解每一个条件为什么被需要。
>
>数值分析中有一个特点，给出的公式往往是充分的。顶层应用时，即使没有满足定理的条件，但我们还是有可能选择相信它。而在底层处理时，我们才会格外注意它的必要性。

#### 不动点定理：Corollary
>
>如果 $g$ 满足了不动点定理，那么迭代误差的范围为：
>$$
>|p_n-p|\le\frac{1}{1-k}|p_{n+1}-p_n|\quad,\quad |p_n-p|\le\frac{k^n}{1-k}|p_1-p_0|
>$$

### 牛顿法

牛顿法也属于一种不动点方法。它的思路是把一个非线性函数线性化。
$$
0=f(p)\approx f(p_0)+f'(p_0)(p-p_0)\quad,\quad p\approx p_0-\frac{f(p_0)}{f'(p_0)}
$$

#### 定理

>若 $f$ 在 $[a,b]$ 二阶连续，且存在 $p\in[a,b]$ 使得 $f(p)=0,f'(p)\ne 0$，那么就存在一个 $\delta > 0$，使得任意初值 $p_0\in[p-\delta,p+\delta]$ 都可以满足 $p_{n+1}=p_n-\frac{f(p_n)}{f'(p_n)}$ 收敛到 $p$。

* 由 $f'(p)\ne0$ 知 $g(x)=x-\frac{f(x)}{f'(x)}$ 在 $p$ 的邻域中连续。
* $g'(x)=\frac{f(x)f''(x)}{f'(x)^2}$ 在 $p$ 的邻域中趋于零，只要 $f''(x)$ 连续且有限。
* 利用不动点定理知存在一个邻域使得收敛。
