---
title: 数值分析
description: 数值分析笔记
pubDate: 2025-02-19
updatedDate: 2025-02-19
tags: ["numerical analysis", "note"]
category: "课程笔记"
---

## Introduction

使用计算机计算和现实计算有一个显著差别：计算机计算的精度是有限制的。我们有不同的
数据结构，带来不同的计算精度。数值分析这门课要求我们求出精度足够好的结果。它会告
诉我们一些近似算法，同时也告诉我们，什么时候它们能用，什么时候又不能用。

我们轻而易举地就能想清楚加减乘除的原理。然而，我们可能没有注意
$\sin,\cos,\tan,\ln$ 是怎么实现的？数值分析这门课可以告诉我们背后的原理。

> 一个自然的想法：泰勒展开

## 数学上的准备

怎么求一个积分？简单的想法是把被积函数泰勒展开转化成多项式，然后利用其便于求积分
的特性求解。然而，泰勒展开往往是无限的，这就需要我们规定一个提前结束的时机，这也
引入了一个相当于泰勒余项(**Remainder**)的**误差**。这个误差就是我们需要注意的。

而且，一个棘手的点是：我们没有办法直接和真值进行比较！

另一个棘手的点是：每一个数值本身都与它自己的真值有误差，这也引入了新的误差！我们
需要为每一个数据保留多少位，这也相应地成为了一个问题。

### 误差 Errors

- Truncation Error：与时间有关的一个误差。它代表近似数学引入的误差。

> 显式的操作，经典的就是一个`for`循环

- Roundoff Error：与空间有关的一个误差。它代表数字在计算机中的表达和数字本身的
    误差。

> 数据背后的误差

为了讨论方便，我们用十进制来表示数字。对于一个不能直接以有限数位表示的数字，有两
种方式处理精度：

- 四舍五入(Rounding)
- 直接砍掉精度数位后面的位数(Chopping)
- 往上取

> 大学老师给分(不是)

误差也分为绝对误差(absolute error)和相对误差(relative error)

而有效数字(siginificant digits)应该是一个相对误差概念。可以注意到，对应数值的部
分被移到了科学计数法中的指数部分。

> 有了有效数字的概念，我们应该把数字 0.123 看成 $0.123\pm\epsilon_1$ 使用四舍五
> 入的方法时，有效数字 0.1 的相对误差是 50%

那么，有一个现象，就是两个相近的数字相减之后，有效位数减小时，相对误差会显著增
加。

将一个数除以一个很小的数，绝对误差会放大。这一点是符合直觉的。一个想法是把绝对误
差看成两个数字的函数，然后取关于分母的导数，如果导数很大，那么就说明分母的轻微变
化会带来较大的变化，也就是较大的误差。对于相对误差，也可以尝试以这样的方法进行分
析。

计算的约化也要注意，计算机是每一个单元运算都会进行约化的，不能直接对最终结果进行
约化。

也正是因此，虽然对单个数字而言，Rounding 会更精确，但是对于一个一连串的算式而
言，未必。

> 我们此时也自然地想到，解不是确定值，也可能不是个区间，而应该是一个概率密度分布
> 中的某个可能值。

也还是因此，对于同一个算式的不同表达，比如将一个算式通过一些方式结合，分配，也可
以导致不同的误差。减少乘除的次数，有可能减少误差。减少单元计算的数量，也有可能减
小误差。

> 数学上等价，不等于数值分析方法上等价！

我们可以手动求导来分析误差，也可以用一些自动求导的工具来分析计算式的误差。

### 算法和收敛 Algorithms and Convergence

当一个算法中，原始数据的较小变化只引起较小的终解的变化时，它是 stable 的；否则，
它是 unstable 的。当它对于某些原始数据 stable 时，它是 conditionally stable 的。

设初始误差为 $E_1$，当做连续的 n 次操作时，如果误差 $E_n$ 约为 $E_1$ 的常数倍
时，说误差的增长是 linear 的。如果 $E_n$ 约为 $E_1$ 的以常数为底的指数倍时，则说
误差的增长是 exponent 的。

## 一元方程的求解

### 二分法

能使用二分法的前提是可排序。比如说，复数就很难使用二分，因为它没有既定的序。

二分法一定要除以二吗？不一定。只要区间收敛就好。

- 取中间位置时应该用`p=a+(b-a)/2`。
- 判断取左边界还是右边界时，需要用`sign()`，而非直接相乘看是否小于 0。
- 函数值需要考虑溢出问题。比如说，一个指数函数就容易出现溢出，即使它的横坐标是
    没溢出的。

如果二分法的区间取的过大，可能会忽略函数的根，如一个先增后减的区间，两侧都小于
零，就会误认为中间没解了。

### 不动点迭代

把方程的根转化成一个等效的等式：$f(x)=0 \Leftrightarrow x=g(x)$。$g$ 的不动点是
$f$ 的根。

#### 不动点定理：Self

> 令 $g$ 是一个在 $[a,b]$ 连续的函数，且在其中 $g(x)\in[a,b]$。若对于它的导函数
> $g'$，存在一个常数 $k\in(0,1)$ 使得开区间内任意的 $x$，有 $|g'(x)|\le k$，则对
> 任意的 $p_0\in[a,b]$，序列 $p_n=g(p_{n-1})$ 收敛到唯一的不动点 $p\in[a,b]$。

- 利用中间值定理，证明存在不动点。
- 利用中值定理，证明不动点唯一。
- 利用值域被定义域包含的条件，保证迭代过程中，$g(x)$ 的结果始终在定义域中。
- 利用中值定理，证明迭代确实是收敛于那个存在且唯一的不动点。

这里的存在一个 $k\in(0,1)$ 很重要，这把 $g'(x)$ 和 1 隔开了，避免了极限为 1 的情
况。

> 看证明是有利于记忆定理的。在看证明的过程中，可以理解每一个条件为什么被需要。
>
> 数值分析中有一个特点，给出的公式往往是充分的。顶层应用时，即使没有满足定理的条
> 件，但我们还是有可能选择相信它。而在底层处理时，我们才会格外注意它的必要性。

#### 不动点定理：Corollary

> 如果 $g$ 满足了不动点定理，那么迭代误差的范围为：
>
> $$
> |p_n-p|\le\frac{1}{1-k}|p_{n+1}-p_n|\quad,\quad |p_n-p|\le\frac{k^n}{1-k}|p_1-p_0|
> $$

### 牛顿法

牛顿法也属于一种不动点方法。它的思路是把一个非线性函数线性化。

$$
0=f(p)\approx f(p_0)+f'(p_0)(p-p_0)\quad,\quad p\approx p_0-\frac{f(p_0)}{f'(p_0)}
$$

#### 定理

> 若 $f$ 在 $[a,b]$ 二阶连续，且存在 $p\in[a,b]$ 使得 $f(p)=0,f'(p)\ne 0$，那么
> 就存在一个 $\delta > 0$，使得任意初值 $p_0\in[p-\delta,p+\delta]$ 都可以满足
> $p_{n+1}=p_n-\frac{f(p_n)}{f'(p_n)}$ 收敛到 $p$。

- 由 $f'(p)\ne0$ 知 $g(x)=x-\frac{f(x)}{f'(x)}$ 在 $p$ 的邻域中连续。
- $g'(x)=\frac{f(x)f''(x)}{f'(x)^2}$ 在 $p$ 的邻域中趋于零，只要 $f''(x)$ 连续
    且有限。
- 利用不动点定理知存在一个邻域使得收敛。

### 作业-2

#### P54-T13

> 找到一个迭代次数的范围，使得使用二分法解 $[1,2]$ 上的方程 $x^3 -x-1=0$ 时，解
> 的精确度有 $10^{-4}$。同时，给出这个解。

此题主要考虑的是二分法的误差范围。当对 $[a,b]$ 进行二分时，第一次二分迭代的结果
为 $a+\frac{b-a}{2}$，$\epsilon\le\frac{b-a}{2}$。易知，第 $n$ 次二分迭代的误差
范围为 $\epsilon\le\frac{b-a}{2^n}$，此处只需取 $n=14$。具体求解过程略。

#### P54-T15

> 令 $p_n=\sum_{k=1}^{n}\frac{1}{k}$，证明 $p_n$ 是发散 diverge 的，即使
> $\lim_{n\rightarrow\infty}(p_n-p_{n-1})=0$。

这算是很经典的题目了，典型的方法有积分放缩。这里则采取证明连续多项的和拥有固定下
界的方法：

$$
\frac{1}{k}+\frac{1}{k+1}\ldots+\frac{1}{2k-1}\gt k\cdot\frac{1}{2k}=\frac{1}{2}
$$

因此总能找到 $p_{2k-1}>p_{k}+\frac{1}{2}$，故 $p_n$ 是发散的。

#### P64-T3

> ![alt text](../../../assets/mdPaste/numericalAnalysis/image.png) 它们被用于计
> 算 $21^{\frac{1}{3}}$。根据收敛速度，将它们排序。假设 $p_0=1$。

a. 这是一个比较普通的不动点方法，直接对

$$
f(x)=\frac{20x}{21}+\frac{1}{x^2}
$$

求导，得

$$
f'(x)=\frac{20}{21}-\frac{2}{x^3}\in[-\frac{22}{21},\frac{6}{7})
$$

这看起来有些危险，我们不妨先迭代一次，得到 $p_1=\frac{41}{21}$，如果把这看成新的
迭代起点，那么可以发现 $f'(x)$ 的范围被控制住了，且拥有明确的上下界。那么，根据
不动点定理的推论，可以得出误差的范围为

$$
O(k^n) \ge O((f'(\frac{41}{21}))^n)\approx O((f'(2))^n)=O((\frac{59}{84})^n)
$$

b. 通过观察可以发现，这是牛顿法，原函数即为

$$
f(x)=x^3-21
$$

关于牛顿法，有这样一件事情：

> 牛顿法的迭代公式为
>
> $$
> p_{n+1}=p_n-\frac{f(p_n)}{f'(p_n)}
> $$
>
> 设迭代终点为 $r$，记 $\epsilon_n=p_n-r$，则根据泰勒展开式，我们有：
>
> $$
> \epsilon_{n+1}=\epsilon_n-\frac{f'(r)\epsilon_n+\frac{1}{2}f''(r)\epsilon_n^2+O(\epsilon_n^3)}{f'(r)+f''(r)\epsilon_n+O(\epsilon_n^2)}=\frac{f''(r)}{2f'(r)}\epsilon_n^2
> $$
>
> 这也就是所谓的牛顿法具有**二次收敛**的性质，这个收敛速度已经很快了。
>
> 本选项就是一个二次收敛的样例。
>
> 需要注意的是，当出现重根， $f'(x)=0$，此时二次收敛不再成立。

c. 看起来很复杂，我们直接尝试代入，然后发现 $p_1=0,p_{k>1}=0$，可知压根收敛不到
$21^{\frac{1}{3}}$。

d. 可以设 $p_n=21^{k_n}$，则有

$$
21^{k_n}=21^{\frac{1-k_{n-1}}{2}}\Rightarrow k_n=\frac{1-k_{n-1}}{2}\Rightarrow k_n-\frac{1}{3}=-\frac{1}{2}(k_{n-1}-\frac{1}{3})
$$

可知 $k_n$ 的误差为 $O(\frac{1}{2}^n)$，那么

$$
p_n=21^{\frac{1}{3}+O(\frac{1}{2^n})}=21^{\frac{1}{3}}\cdot(21^{O(\frac{1}{2^n})})=21^{\frac{1}{3}}(1+\ln(21)\cdot 21^{O(\frac{1}{2^n})}\frac{1}{2^n}+O(\frac{1}{2^{2n}}))\approx21^{\frac{1}{3}}(1+\ln(21)\frac{1}{2^n})
$$

故误差为 $O(\frac{1}{2^n})$。

综上，排序为 $b>d>a>c$。

#### P65-T19

> ---
>
> 1. 利用不动点定理，证明当 $x_0\gt\sqrt{2}$时，
>
> $$
> x_n=\frac{1}{2}x_{n-1}+\frac{1}{x_{n-1}},\qquad \text{for } n\ge 1
> $$
>
> 收敛到 $\sqrt{2}$，
>
> 2. 利用“当 $x_0\ne\sqrt{2}$，$0< (x_0-\sqrt{2})^2$”，证明：当
>     $0\le x_0\le\sqrt{2}$，有 $x_1\gt\sqrt{2}$。
> 3. 利用 (1),(2) 的结果，证明 (a) 中的式子收敛到 $\sqrt{2}$，只要 $x_0\gt 0$。

1. 记 $f(x)=\frac{1}{2}x+\frac{1}{x}$，当 $\sqrt{2}<x\le x_0$ 时，有
   $\sqrt{2}<\frac{1}{2}x+\frac{1}{x}<x_0$，即 $f(x)\in(\sqrt{2},x_0)$。函数连续
   性显然，再由 $f'(x)=\frac{1}{2}-\frac{1}{x^2}\in(0,\frac{1}{2})$ 知存在
   $k\in(0,1)$。综上，已满足不动点定理。
2. 题意估计是要我们配方，不过基本不等式易得了。
3. 首先，利用 (2) 中结果，当 $x_0\in(0,\sqrt{2})$ 时，不妨先迭代一次，把迭代结果
   看成新的 $x_0>\sqrt{2}$。然后，由 (1) 易得收敛至 $\sqrt{2}$。
   $x_0\in(\sqrt{2},\infty)$ 时亦然。

### 对迭代方法的误差分析

> 假设 $\{p_n\}$ 是一个收敛到 $p$ 的序列，如果存在正常数 $\alpha$ 和 $\lambda$
> 使得
>
> $$
> \lim_{n\rightarrow \infty}\frac{|p_{n+1}-p|}{|p_n-p|^\alpha}=\lambda
> $$
>
> 则说 $\{p_n\}$ 对 $p$ 的收敛阶至少为 $\alpha$

比如说，牛顿法就是一个至少二阶收敛的方法(当不存在重根)。

下面是一个可以确定收敛阶阶数的定理：

> 设 $p$ 是 $g(x)$ 的一个不动点，若在 $p$ 的邻域内 $g(x)$ $\alpha \ge 2$ 阶连
> 续，且满足
>
> $$
> g'(p)=g^{(2)}(p)=\ldots g^{(\alpha-1)}(p)=0,g^{(\alpha)}\ne 0
> $$
>
> 则 $g(x)$ 的不动点迭代的收敛阶为 $\alpha$。

### 重根

对计算机来说，解 $x^2=0$ 远比 $x^2-4x+3=0$ 困难。这是因为，前者要考虑重根，而且
对于计算机来说，这实际上是在求 $x^2=\pm \epsilon$，当 $\epsilon<0$，会出现未定义
的情况。所以说，解方程有可能是不稳定的。这里的一种处理方法是，改而求解
$(x^2-0)^2=0$。

前面我们提到，对于牛顿法而言，重根的存在会导致它的收敛阶低于 $2$。不过，我们可以
做一个修正，也就是构造另一个函数，使得它的根和原函数的根相同，但是在原重根的邻域
内不存在重根。

$$
\begin{align*}
    u(x)&=\frac{f(x)}{f'(x)}\\
    x_{n+1}&=x_n-\frac{u(x_n)}{u'(x_n)}
\end{align*}

$$

> 关于邻域内不存在重根这一点，可以通过把函数 $f(x)$ 写成
>
> $$
> f(x)=(x-p)^k\phi(x)\quad,\quad\phi(p)\ne 0
> $$
>
> 来得出。

### Aitken's Δ² Method

> 对于一个一阶收敛的迭代序列，有
>
> $$
> \frac{p_{n+1}-p}{p_{n}-p}\approx \frac{p_{n+2}-p}{p_{n+1}-p_n}
> $$
>
> 据此，我们可以解出 $p$ 的一个近似解
>
> $$
> p\approx\frac{p_{n+2}p_n - p_{n+1}^2}{p_{n+2} - 2p_{n+1} + p_n}=p_n-\frac{(p_{n+1}-p_n)^2}{p_{n+2}-2p_{n+1}+p_n}
> $$
>
> 如果引入差分的话，就可以写成
>
> $$
> p\approx p_n-\frac{(\Delta p_n)^2}{\Delta^2 p_n}
> $$
>
> 于是，我们在使用一阶收敛的方法时，就可以使用 Aitken's Δ² Method 来加速收敛。

有人可能会考虑把 Aitken's Δ² Method 加速完的结果再作为新的迭代起点，然而这样破坏
了 linear convergence 的条件，是不可取的。

### 作业-3-1

#### P86-T11

> 不动点迭代方法
> $$
> p_{n+1}=g(p_{n})=p_n-\frac{f(p_n)}{f'(p_n)}-\frac{f''(p_n)}{2f'(p_n)}\left[\frac{f(p_n)}{f'(p_n)}\right]^2
> $$
> 拥有性质
> $$
> g'(p)=g''(p)=0
> $$
> 这会得到立方收敛的结果。比较一下平方收敛和立方收敛。

设另一个平方收敛的序列为 $\{q_n\}$，为了便于分析，我们设它们都收敛到 $0$(其实就是移动坐标轴)，且
$$
\frac{p_{n+1}}{p_{n}^3}\approx 0.5 \quad\text{and}\quad\frac{q_{n+1}}{q_n^2}\approx 0.5
$$
可以得出
$$
\begin{align*}
|q_n-0|&\approx (0.5)^{2^n-1}|q_0|^{2n}\\
|p_n-0|&\approx (0.5)^{\frac{3^n-1}{2}}|p_0|^{3n}

\end{align*}
$$

## 求解线性方程组 Linear Systems

### 高斯消元法

回忆在线性代数中我们的做法，使用高斯消元，把矩阵化成上三角的形式，然后一个一个解
出解并回代。

我们可以用一个迭代的思路来理解：我们先把最左列除了第一行的元素清零，然后，根据高斯消元法，我们就不再会对第一行、第一列操作了。这时，我们可以忽略它们，这就相当于是再去解一个新的、阶数减一的线性方程组了。迭代进行到阶数为 $1$ 的时候，解就出来了。

> 消元阶段的乘除法的数量为
> $$
> \begin{align*}
>     &\sum_{k=1}^{n-1}(n-k)(n-k-2)\\
>     &=\frac{n^3}{3}+\frac{n^2}{2}-\frac{5n}{6}
> \end{align*}
> $$
> 进行第 $k$ 次迭代时，需要对 $n-k$ 行做消去操作，每一行需要操作的元素有 $n-k+2$ 个。进行 $n-1$ 次操作后，矩阵阶数变为 $1$。
>
> 回代阶段的乘除法数量为
> $$
> 1+\sum_{i=1}^{n-1}(i+1)=\frac{n^2}{2}+\frac{n}{2}
> $$
> 考虑第 $i$ 次回代需要 $1$ 次除法和 $i$ 次乘法即可。
>
### 作业-3-2

#### P357-T8
>
> ![alt text](mdPaste/numericalAnalysis/image-2.png)
> > Algorithm 6.1
> > ![alt text](mdPaste/numericalAnalysis/image.png)
> > ![alt text](mdPaste/numericalAnalysis/image-1.png)
> >

大致步骤一致，只是在 Step4 部分有所区别：我们需要对 $j=1,\ldots n,j\ne i$ 操作。然后，我们在 Step8 阶段就可以返回所有的解：
$$
x_i=a_{i,n+1}/a_{i,i},i=1,2,\ldots,n
$$

#### P358-T11
>
> ![alt text](mdPaste/numericalAnalysis/image-3.png)

根据上一题，我们可以得出，加减法的次数为
$$
\sum_{i=1}^{n}(n-k+1)(n-1)=\frac{n^3}{2}-\frac{n}{2}
$$
乘除法的次数为
$$
\sum_{i=1}^{n}(n-k+2)(n-1)+n=\frac{n^3}{2}+n^2-\frac{n}{2}
$$

为了便于计算，我们可以都只对乘除法的次数进行比较。高斯消元法需要的乘除法总数
$$
\frac{n^3}{3}+n^2-\frac{n}{3}
$$

故有

| n   | 高斯消元法 (GE) | 高斯–约当法 (GJ) |
|-----|----------------|-----------------|
| 3   | 17             | 21              |
| 10  | 430            | 595             |
| 50  | 44150          | 64975           |
| 100 | 343300         | 509950          |

### 主元法 Pivoting Strategies

#### Partial pivoting/maximal column pivoting

第 $i$ 次迭代时， 选择第 $i$ 列中最小的 $p\gt i$，使得 $|a_{pi}|$ 是最大的。然后把第 $p$ 行和第 $i$ 行交换。这样可以保证除的时候除以一个较大的数。

然而，这个方法有一个问题，即除数大无法保证伸缩系数小。

> 时间复杂度： $O(n^2)$

#### Scaled Partial Pivoting/scaled-column pivoting

不仅仅看 $|a_{pi}|$，也考虑本行中的表现。

我们定义一个 scale factor  $s_p=\max|a_{pj}|$。这表现了这一行中的伸缩系数分子中的最大值。

然后，我们寻找第 $i$ 列中最小的 $p\gt i$，使得 $|\frac{a_{pi}}{s_p}|$ 是最大(即最大的伸缩系数最小)的，然后交换。

但是，这么做也有个问题：每一次高斯消元的递归过程中，后面的每一行都发生了变化。如果我们每一行都这么做，会导致速度很慢。因此，注意 partial 这个词，我们的伸缩系数只在一开始计算，后面都不重新计算了。

> 时间复杂度： $O(n^2)$

#### Complete Pivoting/maximal pivoting

一个想法是，如果在 Scaled Partial Pivoting 中每次递归过程都重新计算 $s_p$，那么时间复杂度会到达立方。既然如此，不如也对列做交换。

对于 $n$ 阶的线性方程组，在第 $i$ 次递归时，会有一个 $n+1-i$ 阶子阵。在这个子阵中，找到最大的元素 $a_{pq}$，然后交换 $i$ 行与 $p$ 行，再交换 $i$ 列与 $q$ 列。

> 时间复杂度： $O(\frac{n^3}{3})$

### 矩阵分解 Matrix Factorization

让我们考虑每一次消元的等价操作：

令 $m_{i1}=\frac{a_{i1}}{a_{11}}(a_{11}\ne 0)$，则有第一次消元等价于将原系数矩阵左乘矩阵 $L_1$:

$$
L_1 =
\begin{pmatrix}
1      &        &        &        & \\
-m_{2,1} & 1      &        &        & \\
\vdots & \vdots & \ddots &        & \\
-m_{n,1} &        &        & 1      &
\end{pmatrix}
$$

依次类推，第 $i$ 次消元等价于左乘 $L_i$:
$$
L_i=
\begin{pmatrix}
1&&&&&\\
&\ddots&&&&\\
&&1&&&\\
&&-m_{i+1,i}&1&&\\
&&\vdots&&\ddots&\\
&&-m_{n,i}&&&1
\end{pmatrix}
$$

既然如此，我们可以把每一个消元操作对应的矩阵先相乘。这样，可以得到一个下三角矩阵。

$$
L=L_{n-1}L_{n-2}\ldots L_1
$$
> 单位下三角矩阵乘与取逆都有封闭性。

这个下三角矩阵只与系数矩阵有关。因此，当系数矩阵一定时，这个方法效率很高。

现在，让我们重新整理一下符号。忘掉上面的 $L$，改取
$$
L=L_1^{-1}L_2^{-2}\ldots L_{n-1}^{-1}
$$
则有
$$
A=LU,U\text{为高斯消元法后得到的系数矩阵}
$$
可以看到，我们把 $A$ 分解成了一个下三角矩阵 $L$ 和一个上三角矩阵 $U$ 的乘积。

如果我们在度量上做限制，让 $L$ 为一个单位下三角矩阵，那么这样的分解就是唯一的。

### 特殊矩阵 Special Types of Matrices

- 严格对角占优矩阵 Strictly Diagonally Dominant Matrix：每一行中，对角线元素绝对值严格最大。严格对角占优矩阵是非奇异 nonsingular 的。且执行高斯消元法时不需要置换行或列，其解在舍入误差上是稳定的。

> 直觉上，严格对角占优矩阵类似于单位阵。因此，它会有比较好的性质。

- 正定矩阵 Positive Definite Matrix：对 $\forall x\ne \vec{0}, x^{-1}Ax>0$ 且 $A$ 是对称 symmetric 的.

  - 如果一个矩阵是正定的,那么它的逆也是正定的.
  - 正定矩阵的对角线元素严格大于 $0$.

当给了矩阵的特殊性质，我们就可以针对性质给出特定的优化算法。

#### 正定矩阵的优化算法

当 $A$ 是正定矩阵时，显然，它可以分解成 $B\Lambda B^T$ 的形式，其中 $B$ 为单位下三角矩阵， $\Lambda$ 为对角线元素均大于零的对角阵。另外，我们还有
$$
U=\Lambda\tilde{U}
$$
其中 $\Lambda$ 是以 $u_{ii}$ 为对角元素的对角阵，而 $\tilde{U}$ 则因此变成了一个单位上三角矩阵。注意到 $L$ 为一个单位下三角矩阵，则只能有 $L=\tilde{U}^{T}$

又因为 $\Lambda$ 对角线元素均大于零，因此它可以被分解为 $\Lambda^{\frac{1}{2}}\Lambda^{\frac{1}{2}}$。那么，我们进行再整理，则有
$$
A=\tilde{L}\tilde{L}^{T},\tilde{L}=L\Lambda^{\frac{1}{2}}
$$

使用 **Choleski's Method**，可以快速地计算出 $\tilde{L}$，从而完成线性方程组的求解。

![alt text](mdPaste/numericalAnalysis/image-4.png)

#### 三对角矩阵的优化算法

Thomas 算法：

![alt text](mdPaste/numericalAnalysis/image-5.png)

需要注意的是，一旦 $\exists\alpha_i =0$，则 Thomas 算法失效(但不意味着这个方程不可解)。

> 当 $A$ 是三对角矩阵，且它是 diagonally dominant 的(注意没有要求严格)，且
> $$
> |b_1| >|c_1| >0,|b_n| > |a_n| >0, a_i\ne 0, c_i \ne 0
> $$
> 则 $A$ 非奇异，此时方程可用 Thomas 算法求解。
>
> 当 $A$ 是三对角矩阵且严格对角占优时，方程一定可用 Thomas 算法求解。
>
> 上述两种情况下，Thomas 算法是稳定的，因为所有的中间值会受主对角线元素的约束。
>
> Thomas 算法的时间复杂度为 $O(n)$。

### 矩阵代数中的迭代方法 Iterative Techniques in Matrix Algebra

我们把 $A\vec{x}=\vec{b}$ 转换成迭代形式  $\vec{x}=T\vec{x}+\vec{c}$.为了能够迭代,我们先需要进行数学上的定义.

我们定义向量的范数 norm.范数需要满足:
$$
\begin{aligned}
\text{(1) 非负性：} \quad & \|x\| \ge 0 \quad \text{且} \quad \|x\|=0 \iff x=0, \\
\text{(2) 齐次性：} \quad & \|\alpha x\| = |\alpha| \, \|x\|, \quad \forall \alpha\in\mathbb{R}, \\
\text{(3) 三角不等式：} \quad & \|x+y\| \le \|x\| + \|y\|, \quad \forall x,y.
\end{aligned}
$$

对于某一个范数定义,如果一个迭代序列 $\vec{x_k}$ 满足  $\|\vec{x_k}-\vec{x}\|$ 收敛于 $0$,则说 $\vec{x_k}$ 收敛到 $\vec{x}$.

在有限维向量空间中，不同范数之间总是“等价”的。也就是说，对于任意两个范数 $\|\cdot\|_a$ 和 $\|\cdot\|_b$，存在正的常数 $c$ 和 $C$，使得对所有 $x$ 都有

$$
c \, \|x\|_a \le \|x\|_b \le C \, \|x\|_a.
$$

这说明：

- 如果一个迭代序列在范数 $\|\cdot\|_a$ 下收敛，那么在任意其他范数 $\|\cdot\|_b$ 下也收敛；
- 收敛的快慢（误差量级）在不同范数下最多相差一个常数因子，不影响“收敛阶”的讨论。

因此，在数值算法和迭代方法中，我们通常只选用一种范数来分析误差，而不必担心选哪一种范数会改变收敛性质。

### Homework-1

#### P397-T7

> ![alt text](mdPaste/numericalAnalysis/image-6.png)

#### Read the proofs on P401-402

> ![alt text](mdPaste/numericalAnalysis/image-7.png)


#### P412-T17
